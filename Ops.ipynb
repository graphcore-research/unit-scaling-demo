{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7fa556-8d41-4917-ae78-daa8d2482459",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi=False\n",
    "import collections\n",
    "from typing import *\n",
    "import functools as ft\n",
    "import torch as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165bdbb6-b088-42ef-acfb-079730de9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shape = Tuple[int, ...]\n",
    "\n",
    "def bootstrap_scaling_factors(op: Callable[..., T.Tensor], args: Dict[str, Shape],\n",
    "                              n_reps: int) -> Dict[str, np.ndarray]:\n",
    "    results = collections.defaultdict(list)\n",
    "    for _ in range(n_reps):\n",
    "        inputs = [T.tensor(v, requires_grad=True)\n",
    "                  if isinstance(v, np.ndarray) else\n",
    "                  T.randn(v, requires_grad=True)\n",
    "                  for v in args.values()]\n",
    "        output = op(*inputs)\n",
    "        output.backward(T.randn_like(output))\n",
    "        results[\"y\"].append(float(1 / T.std(output)))\n",
    "        for arg, input in zip(args, inputs):\n",
    "            results[f\"grad_{arg}\"].append(float(1 / T.std(input.grad)))\n",
    "    return {k: np.array(v) for k, v in results.items()}\n",
    "\n",
    "def show(factors: Dict[str, np.ndarray]) -> None:\n",
    "    for k, samples in factors.items():\n",
    "        samples = np.array(samples)\n",
    "        confidence = 2 * np.std(samples) / np.sqrt(len(samples) - 1) if 2 <= samples.size else float(\"NaN\")\n",
    "        print(f\"   {k:<10} {np.mean(samples):<8.4g} ± {confidence:.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04f596e-788e-44cc-9518-0331eba837a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### gelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglaso/work/ThreeRs/.venv/lib/python3.6/site-packages/torch/autograd/__init__.py:149: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   y          1.701    ± 0.00035\n",
      "   grad_x     1.481    ± 0.00035\n",
      "### tanh\n",
      "   y          1.593    ± 0.00013\n",
      "   grad_x     1.468    ± 0.00027\n",
      "### sigmoid\n",
      "   y          4.802    ± 0.00049\n",
      "   grad_x     4.722    ± 0.00077\n"
     ]
    }
   ],
   "source": [
    "for activation in [T.nn.functional.gelu, T.tanh, T.sigmoid]:\n",
    "    print(f\"### {activation.__name__}\")\n",
    "    show(bootstrap_scaling_factors(activation, dict(x=(int(1e6),)), n_reps=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7018e319-d434-4f8f-9118-9d9258cbc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### relu\n",
      "Expected:\n",
      "   y          1.713    ± nan\n",
      "   grad_x     1.414    ± nan\n",
      "Simulated:\n",
      "   y          1.713    ± 0.00037\n",
      "   grad_x     1.414    ± 0.00027\n"
     ]
    }
   ],
   "source": [
    "print(\"### relu\")\n",
    "print(\"Expected:\")\n",
    "show(dict(y=(2 / (1 - 1/np.pi)) ** 0.5, grad_x=2 ** 0.5))\n",
    "print(\"Simulated:\")\n",
    "show(bootstrap_scaling_factors(T.nn.functional.relu, dict(x=(int(1e6),)), n_reps=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbade3e0-1343-4264-abb5-138cb7e86eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### reduce_sum\n",
      "   y          0.04419  ± nan\n",
      "   grad_x     1        ± nan\n",
      "   y          0.04421  ± 6.8e-05\n",
      "   grad_x     0.9997   ± 0.0013\n"
     ]
    }
   ],
   "source": [
    "print(\"### reduce_sum\")\n",
    "N = 512\n",
    "show(dict(y=N ** -0.5, grad_x=1))\n",
    "show(bootstrap_scaling_factors(ft.partial(T.sum, dim=1), dict(x=(int(1e4), N)), n_reps=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225c55dc-e4e5-4e03-a3f0-5023ce6a9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### weighted_sum\n",
      "   sy         0.9957   ± nan\n",
      "   sgrad_x    0.9998   ± nan\n"
     ]
    }
   ],
   "source": [
    "print(\"### weighted_sum\")\n",
    "weight = T.rand(1000, 512)\n",
    "x = T.randn_like(weight, requires_grad=True)\n",
    "y = T.sum(weight * x, 1)\n",
    "y.backward(T.randn_like(y))\n",
    "\n",
    "with T.no_grad():\n",
    "    show(dict(\n",
    "        sy=T.std(T.sum(weight ** 2, 1) ** -0.5 * y),\n",
    "        sgrad_x=T.std(weight ** -1 * x.grad),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6668172-b7c3-460d-bf53-a9703e4d8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### matmul\n",
      "   y          0.0625   ± nan\n",
      "   grad_x     0.04419  ± nan\n",
      "   grad_w     0.08839  ± nan\n",
      "   y          0.0625   ± 2e-05\n",
      "   grad_x     0.0442   ± 1.5e-05\n",
      "   grad_w     0.08839  ± 2.8e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"### matmul\")\n",
    "B, M, N = 128, 256, 512\n",
    "show(dict(y=M ** -0.5, grad_x=N ** -0.5, grad_w=B ** -0.5))\n",
    "show(bootstrap_scaling_factors(T.matmul, dict(x=(B, M), w=(M, N)), n_reps=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26e56a3-b34c-4627-9b59-cc9d164a54c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### layer_norm\n",
      "   y          1        ± nan\n",
      "   grad_x     1        ± nan\n",
      "   grad_w     0.07071  ± nan\n",
      "   grad_b     0.07071  ± nan\n",
      "   y          1        ± 1.2e-08\n",
      "   grad_x     0.9992   ± 0.00061\n",
      "   grad_w     0.07089  ± 0.00046\n",
      "   grad_b     0.07093  ± 0.00047\n"
     ]
    }
   ],
   "source": [
    "print(\"### layer_norm\")\n",
    "B, N = 200, 512\n",
    "show(dict(y=1, grad_x=1, grad_w=B ** -0.5, grad_b=B ** -0.5))\n",
    "show(bootstrap_scaling_factors(\n",
    "    lambda x, w, b: T.nn.functional.layer_norm(x, (N,), w, b),\n",
    "    dict(x=(B, N), w=np.ones(N, np.float32), b=np.zeros(N, np.float32)), n_reps=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee3910a-604d-4256-aa65-5c8e2fc2244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### softmax_ce\n",
      "   y          1        ± nan\n",
      "   grad_x     2.5      ± nan\n",
      "   y          inf      ± nan\n",
      "   grad_x     2.501    ± 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglaso/work/ThreeRs/.venv/lib/python3.6/site-packages/numpy/core/_methods.py:202: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "print(\"### softmax_ce\")\n",
    "B, S = 1000, 5\n",
    "show(dict(y=1, grad_x=S/np.sqrt(S-1)))\n",
    "show(bootstrap_scaling_factors(\n",
    "    lambda x: T.nn.functional.cross_entropy(x, T.randint(S, size=(B,)), reduction=\"none\"), dict(x=np.zeros((B, S), np.float32)), n_reps=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
